
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1, maximum-scale=1" name="viewport">
    <!--    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum -scale=1.0, user-scalable=no" />-->
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <link href="style.css?v=1222" rel="stylesheet">
    <link href="icons/favicon.png" rel="icon">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Raleway:300,400" rel="stylesheet">
    <title>
        Khurram Azeem Hashmi
    </title>
    
</head>

<body>


<div class="container">
   

    <div class="bio">
    <div class="row">

          <div class="col-md-3">


                <center>
                    <img , class="dp", alt="Me" class="img-responsive img-rounded" src="figures/me.png" width="100%">
                </center>

            </div>
        
        <div class="col-md-9">
            
            <h1 align="center">Hi, I am Khurram!</h1>
    <h4 align="center"><a href="mailto:khurram_azeem.hashmi@dfki.de">khurram_azeem.hashmi@dfki.de</a></h4>
            <p class="text-justify">

                I am a researcher at the German Research Center for Artificial Intelligence <a href="https://dfki.de/", target="_blank">(DFKI)</a> and a PhD Candidate at RPTU Kaiserlautern-Landau. My research focuses on developing algorithms and models that enable machines to "see" and understand the visual world. 
                I'm particularly interested in applying deep learning techniques to solve problems in computer vision, such as imporving instance-level representations in Videos and other challenging ennvironments. In my research, I explore ways to make these models more efficient, robust, and interpretable.
                
                I obtained my bachelor's degree in Computer Science from University of Computer and Emerging Sciences, Pakistan, in 2016, and the M.S. degree and my master's degree in Artificial Intelligence from the Technical University of Kaiserslautern. Currently, I'm pursuing my PhD at RPTU Kaiserlautern-Landau., where I work closely with Prof. Dr. Didier Stricker on developing new approaches for visual recognition.

                In my free time, I enjoy tinkering with new machine learning models, reading novel research methods, and exploring the great outdoors. I'm always on the lookout for new challenges and opportunities to learn, so feel free to get in touch with me if you have any questions or suggestions!
            </p>
    

            <div align="center">
            <br>
                <a href="CV.pdf" target="#">
                    CV
                </a>
                /
                <a href="https://scholar.google.com/citations?user=0CN11t4AAAAJ&hl=en" target="#">Google Scholar
                </a>
                /
                <a href="https://github.com/khurramHashmi" target="#">
                    Github
                </a>
                  /
                <a href="https://twitter.com/khurramhashmi3" target="#">
                    Twitter
                </a>
            </div>
        </div>
        </div>

      

        </div>
<div class="panel panel-success">

<div class="publications">


    
    <div class="row">
        <div class="col-md-3">
        </div>
        <div class="col-md-9">

        <h2 align="center">Seletected Publications</h2>

        </div>
    </div>
    
    <div class="paper">
    
        <div class="row">
            <div class="col-md-3">
                <div class="paper-icon">
                    <img alt="Me" class="img-responsive img-rounded" src="figures/boxmask.gif">
                </div>
            </div>


            <div class="col-md-9 ">

                     <span class="article_title">
                        BoxMask: Revisiting Bounding Box Supervision for Video Object Detection
                     </span>
                <div class="authors">
                    <b>K.A. Hashmi</b>, A.Pagani. D.Stricker, M.Z. Afzal
                </div>

                </p>
                <p class="text-justify"> We propose BoxMask, which effectively learns discriminative representations by incorporating class-aware pixel-level information. We simply consider bounding box-level annotations as a coarse mask for each object to supervise our method. The proposed module can be effortlessly integrated into any region-based detector to boost detection.
                    <br>
                <table style="width:98%">
                    <tr>
                        <td>
                            <a  href="https://openaccess.thecvf.com/content/WACV2023/html/Hashmi_BoxMask_Revisiting_Bounding_Box_Supervision_for_Video_Object_Detection_WACV_2023_paper.html"
                               target="_blank">Paper</a>
                        </td>
                        <td>
                            <div align="right" class="venue"><i>WACV2023</i></div>
                        </td>
                    </tr>
                </table>

            </div>
        </div>
    </div>
    <div class="paper">
    
        <div class="row">
            <div class="col-md-3">
                <div class="paper-icon">
                    <img alt="Me" class="img-responsive img-rounded" src="figures/sparse_vod.gif">
                </div>
            </div>


            <div class="col-md-9 ">

                     <span class="article_title">
                        Spatio-Temporal Learnable Proposals for End-to-End Video Object Detection
                     </span>
                <div class="authors">
                    <b>K.A. Hashmi</b>, D.Stricker, M.Z. Afzal
                </div>

                </p>
                <p class="text-justify"> This paper presents the novel idea of generating object proposals by leveraging temporal information for video object detection. The feature aggregation in modern region-based video object detectors heavily relies on learned proposals generated from a single-frame RPN. This imminently introduces additional components like NMS and produces unreliable proposals on low-quality frames. To tackle these restrictions, we present SparseVOD, a novel video object detection pipeline that incorporates the attention-guided Semantic Proposal Feature Aggregation module to enhance object feature representation before detection. The proposed SparseVOD effectively alleviates the overhead of complicated post-processing methods and makes the overall pipeline end-to-end trainable. 
                    <br>
                <table style="width:98%">
                    <tr>
                        <td>
                            <a  href="https://bmvc2022.mpi-inf.mpg.de/18/"
                               target="_blank">Paper</a>
                        </td>
                        <td>
                            <div align="right" class="venue"><i>BMVC2022</i></div>
                        </td>
                    </tr>
                </table>

            </div>
        </div>
    </div>
    <div class="paper">
    
        <div class="row">
            <div class="col-md-3">
                <div class="paper-icon">
                    <img alt="Me" class="img-responsive img-rounded" src="figures/att_VOD.png">
                </div>
            </div>


            <div class="col-md-9 ">

                     <span class="article_title">
                        Attention-Guided Disentangled Feature Aggregation for Video Object Detection
                     </span>
                <div class="authors">
                    S. Muralidhara, <b>K.A. Hashmi</b>, A.Pagani., M. Liwicki, D.Stricker, M.Z. Afzal
                </div>

                </p>
                <p class="text-justify"> This paper proposes to disentangle the attention guided temporal aagregation among video frames to improve video object detection. 
                    <br>
                <table style="width:98%">
                    <tr>
                        <td>
                            <a  href="https://www.mdpi.com/1424-8220/22/21/8583"
                               target="_blank">Paper</a>
                        </td>
                        <td>
                            <div , align="right" class="venue"><i>Sensors</i></div>
                        </td>
                    </tr>
                </table>

            </div>
        </div>
    </div>
    <div class="paper">
    
        <div class="row">
            <div class="col-md-3">
                <div class="paper-icon">
                    <img alt="Me" class="img-responsive img-rounded" src="figures/table_str.jpg">
                </div>
            </div>


            <div class="col-md-9 ">

                     <span class="article_title">
                        Guided Table Structure Recognition Through Anchor Optimization
                     </span>
                <div class="authors">
                    <b>K.A. Hashmi</b>, D.Stricker, M. Liwicki, M.Z. Afzal
                </div>

                </p>
                <p class="text-justify"> This paper presents the novel approach towards table structure recognition by leveraging the guided anchors. The concept differs from current state-of-the-art systems for table structure recognition that naively apply object detection methods. In contrast to prior techniques, first, we estimate the viable anchors for table structure recognition. Subsequently, these anchors are exploited to locate the rows and columns in tabular images.
                    <br>
                <table style="width:98%">
                    <tr>
                        <td>
                            <a  href="https://ieeexplore.ieee.org/abstract/document/9508971/"
                               target="_blank">Paper</a>
                        </td>
                        <td>
                            <div , align="right" class="venue"><i>IEEE ACCESS</i></div>
                        </td>
                    </tr>
                </table>

            </div>
        </div>
    </div>
    <div class="paper">
    
        <div class="row">
            <div class="col-md-3">
                <div class="paper-icon">
                    <img alt="Me" class="img-responsive img-rounded" src="figures/instance_challenging_env.jpg">
                </div>
            </div>

            <div class="col-md-9 ">

                <span class="article_title">
                        Exploiting Concepts of Instance Segmentation to Boost Detection in Challenging Environments
                </span>
                <div class="authors">
                    <b>K.A. Hashmi</b>, A.Pagani., M. Liwicki, D.Stricker, M.Z. Afzal
                </div>

                </p>
                <p class="text-justify"> Object detection methods face a problem when performed in low light, challenging weather, and crowded scenes, similar to any other task. Such an environment is termed a challenging environment. This paper exploits pixel-level information to improve detection under challenging situations. To this end, we exploit the recently proposed hybrid task cascade network. This network works collaboratively with detection and segmentation heads at different cascade levels. 
                    <br>
                <table style="width:98%">
                    <tr>
                        <td>
                            <a  href="https://ieeexplore.ieee.org/abstract/document/9508971/"
                               target="_blank">Paper</a>
                        </td>
                        <td>
                            <div , align="right" class="venue"><i>Sensors</i></div>
                        </td>
                    </tr>
                </table>

            </div>
        </div>
    </div>
    <div class="paper">
    
        <div class="row">
            <div class="col-md-3">
                <div class="paper-icon">
                    <img alt="Me" class="img-responsive img-rounded" src="figures/castabdetectors.png">
                </div>
<!--                 <div class="paper-icon">
                    <img alt="Me" class="img-responsive img-rounded" src="figures/castab_sc.jpg">
                </div> -->
            </div>

            <div class="col-md-9 ">

                <span class="article_title">
                        CasTabDetectoRS: Cascade Network for Table Detection in Document Images with Recursive Feature Pyramid and Switchable Atrous Convolution
                </span>
                <div class="authors">
                    <b>K.A. Hashmi</b>, A.Pagani., M. Liwicki, D.Stricker, M.Z. Afzal
                </div>

                </p>
                <p class="text-justify">We present CasTabDetectoRS, a novel end-to-end trainable table detection framework that operates on Cascade Mask R-CNN, including Recursive Feature Pyramid network and Switchable Atrous Convolution in the existing backbone architecture. By utilizing a comparativelyightweight backbone of ResNet-50, this paper demonstrates that superior results are attainable without relying on pre- and post-processing methods, heavier backbone networks (ResNet-101, ResNeXt-152), and memory-intensive deformable convolutions.
                    <br>
                <table style="width:98%">
                    <tr>
                        <td>
                            <a  href="https://ieeexplore.ieee.org/abstract/document/9508971/"
                               target="_blank">Paper</a>
                        </td>
                        <td>
                            <div , align="right" class="venue"><i>Sensors</i></div>
                        </td>
                    </tr>
                </table>

            </div>
        </div>
    </div>
    
</div>
<row>
    <hr>
    <div align="center">Khurram Azeem Hashmi. Design inspired by <a href="https://jonbarron.info/">this website</a>.</div>
    <br>
    <br>
</row>
</div>
</body>

</html>

